---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

About Thien Nguyen
======

Dr.Thien Nguyen received his Ph.D. in Robotics from Singapore's [Nanyang Technological University](https://www.ntu.edu.sg/eee) (NTU), and B.Eng with honors from the [Faculty of Electrical and Electronics Engineering](http://dee.hcmut.edu.vn/index.php?route=common/home) (FEEE) at [Ho Chi Minh City University of Technology](https://hcmut.edu.vn/en) (HCMUT) in 2017. From 2017 to 2018, he was a Project Officer at the Nanyang Technological University, Singapore. After completing his PhD in 2023, he works as a Research Fellow at Singapore Centre for Advanced Robotics Technology Innovation (CARTIN). From 02/2024, he works as Vonwiller Postdoctoral Research Associate in Robotics and AI for Precision Agriculture at the Australian Centre for Robotics (ACFR). His research interests include perception and navigation for autonomous mobile robots, with a strong focus on precision agriculture.

- [University of Sydney's Staff profile](https://www.sydney.edu.au/engineering/about/our-people/academic-staff/thienhoang-nguyen.html)
- [ORCID](https://orcid.org/0000-0003-1218-0910)
- [Google Scholar](https://scholar.google.com/citations?user=SfwbVKgAAAAJ&hl=en)
- [LinkedIn](https://sg.linkedin.com/in/thiennguyenhoang)

Highlighted Researches
======

VIRAL-SLAM
------
[Paper](https://ieeexplore.ieee.org/document/9502143) | [YouTube](https://youtu.be/LerAfvZMb7M) | [Patent](https://patents.google.com/patent/WO2022045982A1)

EEE_01                     | NYA_01                    | SBS_01
:-------------------------:|:-------------------------:|:-------------------------:
![](images/demo_eee_01.gif)|![](images/demo_nya_01.gif)|![](images/demo_sbs_01.gif)

**Description**: A comprehensive optimization-based estimator for the 15-D state of an unmanned aerial vehicle (UAV), fusing data from an extensive set of sensors: inertial measurement unit (IMU), ultrawideband (UWB) ranging sensors, and multiple onboard visual-inertial and lidar odometry subsystems, referred to as VIRAL (visual-inertial-ranging-lidar) SLAM.


NTU VIRAL Dataset
------
[Paper](https://journals.sagepub.com/doi/abs/10.1177/02783649211052312?journalCode=ijra) | [Download link](https://researchdata.ntu.edu.sg/dataset.xhtml?persistentId=doi:10.21979/N9/X39LEK) | [Details and instructions](https://ntu-aris.github.io/ntu_viral_dataset/)

UAV                        | UGV                    
:-------------------------:|:-------------------------:
<img src="images/hardware.jpg" width="400">|<img src="images/AGV_VIRAL.png" width="250">


**Description**: A datasets collected from our research Unmanned Aerial Vehicle (UAV) platform, featuring an extensive set of sensors:
- Two 3D LiDARs (Ouster OS1-16 gen 1)
- Two time-synchronized cameras (uEye 1221 LE)
- Multiple IMUs (VectorNav VN100 and Ouster's IMUs)
- Four Ultra-wideband (UWB) nodes on UAV, ranging to three anchor nodes (Humatic P440)
- 3-DoF ground truth obtained from Leica MS60 TotalStation.

The comprehensive sensor suite resembles that of an autonomous driving car, but features distinct and challenging characteristics of aerial operations. The flight tests are conducted in a variety of both indoor and outdoor conditions.
